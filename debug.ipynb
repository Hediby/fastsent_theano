{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lang=\"en\"\n",
    "tokenized=True\n",
    "remote=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "build vocab\n",
      "data size: 3\n",
      "vocab size: 54\n",
      "words: [u'saxophone', u'flat', u'soprano', u'alto', u'walking', u'#195727#', u'#73233#', u'#314843#', u'revised', u'labeled']\n",
      "i2f: [0.0, 0.048872319603449614, 0.07793197470300424, 0.10699162980255886, 0.13605128490211346, 0.1533302592040712, 0.17060923350602894, 0.18788820780798665, 0.2051671821099444, 0.22244615641190213]\n",
      "begin\n",
      "processed: 0\n",
      "finish load pretrain\n",
      "len index_fixe:2\n",
      "index_fixe: [0, 48]\n",
      "create model\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/scipy/lib/_util.py:35: DeprecationWarning: Module scipy.linalg.blas.fblas is deprecated, use scipy.linalg.blas instead\n",
      "  DeprecationWarning)\n",
      "/usr/local/lib/python2.7/dist-packages/numpy/lib/utils.py:95: DeprecationWarning: `scipy.sparse.sparsetools` is deprecated!\n",
      "scipy.sparse.sparsetools is a private module for scipy.sparse, and should not be used.\n",
      "  warnings.warn(depdoc, DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "# -*- coding: utf-8 -*-\n",
    "\"\"\"\n",
    "Created on Wed Feb 24 15:51:31 2016\n",
    "\n",
    "@author: hedi & arame\n",
    "\"\"\"\n",
    "from collections import Counter\n",
    "#import seaborn as sns\n",
    "import numpy as np\n",
    "import sys\n",
    "\n",
    "def indexize(s, w2i,tokenized=True):\n",
    "    res = []\n",
    "    if len(s)==0:\n",
    "        return res\n",
    "    if s[0]==\"#\":\n",
    "        try:\n",
    "            return [w2i[s]]\n",
    "        except:\n",
    "            return res\n",
    "    if tokenized:\n",
    "        s=s.split(\" \")\n",
    "    for w in s:\n",
    "        try:\n",
    "            i = w2i[w]\n",
    "        except:\n",
    "            continue\n",
    "        res.append(i)\n",
    "    return res\n",
    "    \n",
    "class SentenceIt(object):\n",
    "    def __init__(self, path):\n",
    "        self.path = path\n",
    "        self.n_data = 0\n",
    "        \n",
    "    def __iter__(self):\n",
    "        for s in open(path,'r'):\n",
    "            s = u\"%s\" % s.decode('utf-8')[:-1]\n",
    "            if len(s)>0:\n",
    "                self.n_data += 1\n",
    "                yield s\n",
    "            \n",
    "class MinibatchSentenceIt(object):\n",
    "    def __init__(self, path, batch_size, w2i,tokenized):\n",
    "        self.path = path\n",
    "        self.batch_size = batch_size\n",
    "        self.w2i = w2i\n",
    "        self.n_empty = 0\n",
    "        self.i=0\n",
    "        self.tokenized=tokenized\n",
    "        \n",
    "    def __iter__(self):\n",
    "        # we could make it better by:\n",
    "            # - taking overlapping batches\n",
    "            # - randomly sampling batches\n",
    "        minibatch = []\n",
    "        Ls = []\n",
    "        for s in open(path,'r'):\n",
    "            s = u\"%s\" % s.decode('utf-8')[:-1]\n",
    "            s = indexize(s, self.w2i,self.tokenized)\n",
    "            if len(s) == 0:\n",
    "                self.n_empty += 1\n",
    "                continue\n",
    "            if s[0]==\"#\":\n",
    "                l=1\n",
    "            else:\n",
    "                l=len(s)\n",
    "            minibatch.append(s)\n",
    "            \n",
    "            Ls.append(l)\n",
    "            # Here it's savage, maybe find sth smarter and quicker\n",
    "            if len(minibatch)==self.batch_size:\n",
    "                self.i=self.i+1\n",
    "                M = max(Ls)\n",
    "                padded = np.array([np.pad(m, (0,M-l), 'constant') for (m,l) in zip(minibatch, Ls)], dtype='int32')                \n",
    "                minibatch = []\n",
    "                Ls = []\n",
    "                yield padded\n",
    "    \n",
    "if __name__ == '__main__':\n",
    "        \n",
    "    strExtract=\"\"\n",
    "    strToken=\"_tok\" if (tokenized and lang==\"zh\") else \"\"\n",
    "    max_voc=20000\n",
    "    if lang==\"zh\":\n",
    "        path = '/media/data/datasets/wikipedia/entities/bigpage_zh'+strToken+'.txt_line_processed'+strExtract if remote else \"data/dataset\"+strToken+\".txt\"\n",
    "    elif lang==\"en\":\n",
    "        path='/media/data/datasets/wikipedia/entities/bigpage_'+lang+'.txt_line_processed'\n",
    "        \n",
    "    vocab = Counter()\n",
    "    print \"build vocab\"\n",
    "    Ls = []\n",
    "\n",
    "    sentences = SentenceIt(path)\n",
    "    if lang==\"zh\":\n",
    "        for s in sentences:\n",
    "            if s[0]==\"#\":\n",
    "                Ls.append(1)\n",
    "                vocab[s]+=1\n",
    "            else:\n",
    "                if tokenized:\n",
    "                    s=s.split(\" \")\n",
    "                Ls.append(len(s))\n",
    "                for w in s:\n",
    "                    vocab[w] += 1\n",
    "    else:\n",
    "        for s in sentences:\n",
    "            if tokenized:\n",
    "                s=s.split(\" \")\n",
    "                Ls.append(len(s))\n",
    "                for w in s:\n",
    "                    vocab[w] += 1\n",
    "            else:\n",
    "                print \"error: case not possible yet\"\n",
    "                \n",
    "    #sns.distplot(Ls)\n",
    "    n_data = sentences.n_data\n",
    "    print \"data size: \" + str(n_data)\n",
    "    w2i = {}\n",
    "    i2cf = []\n",
    "    i2w = []\n",
    "    f = open('vocab','w')\n",
    "    mc =  vocab.most_common()[:max_voc]\n",
    "    cumFreq=0\n",
    "    \n",
    "\n",
    "    for k,(w,c) in enumerate([('<pad>', 0)] + mc):\n",
    "        cumFreq+=pow(int(c),3./4)\n",
    "        w2i[w] = k\n",
    "        i2cf.append(cumFreq)\n",
    "        i2w.append(w)\n",
    "\n",
    "        f.write(\"%s %f\\n\" % (w.encode('utf-8'),int(c))) \n",
    "    i2f=[cf/float(cumFreq)for cf in i2cf]\n",
    "\n",
    "    f.close()\n",
    "\n",
    "    words=w2i.keys()\n",
    "    words=map(lambda w:w[0],mc)\n",
    "    print \"vocab size: \" + str(len(words))\n",
    "    print \"words: \"+ str(words[:10])\n",
    "    print \"i2f: \"+ str(i2f[:10])\n",
    "\n",
    "    batch_size = 300 if remote else 5\n",
    "    vocab_size = len(i2w)\n",
    "    n_epochs = 500000 if remote else 2\n",
    "    dim=200 if remote else 6\n",
    "    pt=\"_pt\" if lang!=\"en\" else \"\"\n",
    "    \n",
    "    save_every = 1000 if remote else 4\n",
    "\n",
    "    batches = MinibatchSentenceIt(path, batch_size, w2i,tokenized)\n",
    "    \n",
    "    print \"begin\"\n",
    "\n",
    "\n",
    "    i2e={}\n",
    "    index_fixe=[0]\n",
    "    if lang==\"zh\":\n",
    "        pretrainedFile=\"/media/data/datasets/models/word2vec_model/model_bridge/model_zh_ws5_pt_ne5_sa0.0001_mc40.vec\" if remote else \"data/pretrained.txt\"\n",
    "    elif lang==\"en\":\n",
    "        pretrainedFile=\"/media/data/datasets/models/word2vec_model/model_bridge/model_en_ws5_ne5_sa0.0001_mc100.vec\"\n",
    "        \n",
    "\n",
    "    if remote:\n",
    "        sys.path.insert(0, '/home/arame/hakken-api/models/')\n",
    "        import model\n",
    "        import utils\n",
    "        pretrained=model.model(pretrainedFile,max_voc=max_voc)\n",
    "        wordsModel=pretrained.words\n",
    "        floatsModel=pretrained.floats\n",
    "    else:\n",
    "        import utils\n",
    "        wordsModel,floatsModel=utils.loadModel(pretrainedFile)\n",
    "    \n",
    "    print \"finish load pretrain\"\n",
    "     \n",
    "    for word,oldi in wordsModel.items(): \n",
    "        if word in words:\n",
    "            i=w2i[word]\n",
    "            if len(word)>1 and word[0:2]==\"##\":\n",
    "                index_fixe.append(i)\n",
    "            i2e[i]=floatsModel[oldi]\n",
    "    \n",
    "    print \"len index_fixe:\" + str(len(index_fixe))\n",
    "    print \"index_fixe: \"+ str(index_fixe[:10])\n",
    "    \n",
    "    print \"create model\"\n",
    "    lr=0.0025 if remote else 0.01\n",
    "    neg_len=800 if remote else 10\n",
    "    strNeg=\"_neg\"+str(neg_len)\n",
    "    strBs=\"_bs\"+str(batch_size)\n",
    "\n",
    "    saving_path = \"/media/data/datasets/models/word2vec_model/model_fastsent/pickle_\" + lang + pt + \"_fastsent\" + strToken + strBs + strNeg + \".vec\" + strExtract if remote else \"chineseModel\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import theano\n",
    "import numpy as np\n",
    "from time import time\n",
    "import theano.tensor as T\n",
    "import cPickle\n",
    "from theano.tensor.nnet import softmax\n",
    "#dtype = theano.config.dtype\n",
    "from random import random\n",
    "from bisect import bisect\n",
    "\n",
    "def weighted_choice(i2f):\n",
    "    x = random()\n",
    "    i = bisect(i2f, x)\n",
    "    return i\n",
    "dtype='float32'\n",
    "\n",
    "class Model(object):\n",
    "    @classmethod\n",
    "    def load(cls,path):\n",
    "        with open(path,'rb') as f:\n",
    "            params= cPickle.load(f)\n",
    "        w2i,W, V, autoencode= params\n",
    "        return cls(W, V,w2i, autoencode)\n",
    "    \n",
    "    @classmethod\n",
    "    def create(cls, vocab_size, dim,w2i,i2e={}, autoencode=True,cst=0.001):\n",
    "        W = np.vstack((np.zeros(dim),0.01*np.random.randn(vocab_size-1, dim))).astype(dtype)\n",
    "        V = np.vstack((np.zeros(dim),0.01*np.random.randn(vocab_size-1, dim))).astype(dtype)\n",
    "        for i,e in i2e.items():\n",
    "            W[i]=cst*e\n",
    "            V[i]=cst*e\n",
    "        return cls(W,V,w2i,autoencode)   \n",
    "\n",
    "    def save(self, saving_path):\n",
    "        print saving_path\n",
    "        data = [self.w2i,self.W, self.V, self.autoencode]\n",
    "        with open(saving_path,'wb') as f:\n",
    "            cPickle.dump(data, f)\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class FastSent(Model):\n",
    "    def __init__(self, W,V,w2i,autoencode):\n",
    "        self.w2i=w2i\n",
    "        self.W = theano.shared(W, name='W')\n",
    "        self.V = theano.shared(V, name='V')\n",
    "        self.autoencode = autoencode\n",
    "        self.params = [self.W,self.V]\n",
    "        \n",
    "        indexes = T.imatrix('X')\n",
    "        batch_mask = 1-T.eq(indexes, T.zeros_like(indexes))\n",
    "        mask = batch_mask[1:-1]\n",
    "        maskp = batch_mask[:-2]\n",
    "        maskn = batch_mask[2:]\n",
    "        X_indexes = indexes[1:-1]\n",
    "        Yp_indexes = indexes[:-2]\n",
    "        Yn_indexes = indexes[2:]\n",
    "\n",
    "        X = self.W[X_indexes]\n",
    "        Xs = T.sum(X, axis=1)\n",
    "        activations = T.dot(Xs, self.V.T)\n",
    "        # Change this thing so we don't compute softmax for <pad> token\n",
    "        prediction = softmax(activations)\n",
    "        I = [Yp_indexes, Yn_indexes]\n",
    "        M = [maskp, maskn]\n",
    "        if self.autoencode:\n",
    "            I.append(X_indexes)\n",
    "            M.append(mask)\n",
    "        y_true = T.concatenate(I, axis=1)\n",
    "        mask = T.concatenate(M, axis=1)\n",
    "        output = 1e-6+prediction[T.arange(y_true.shape[0]).reshape((-1,1)), \n",
    "                            y_true]\n",
    "        \n",
    "        cost = T.mean(T.sum(-T.log(output)*mask, axis=1))\n",
    "        lr = T.scalar('lr', dtype=dtype)\n",
    "        \n",
    "        self.grads = T.grad(cost, self.params)\n",
    "        # Here is sgd, we could make it better\n",
    "        updates = [(p, p-lr*g) for p,g in zip(self.params, self.grads)]\n",
    "        self._train = theano.function(inputs = [indexes, lr],\n",
    "                                      outputs = [cost,activations,prediction,output,self.grads[1]], \n",
    "                                      #updates=updates, \n",
    "                                      allow_input_downcast=True,\n",
    "                                      on_unused_input='warn')\n",
    "                                     \n",
    "                                      \n",
    "    def train(self, batch_iterator, lr, min_lr, n_epochs, \n",
    "              saving_path, save_every, verbose = True):\n",
    "        n_iter = 0\n",
    "        break_all = False\n",
    "        for epoch in xrange(n_epochs+1):\n",
    "            learning_rate = min_lr + (n_epochs-epoch)*(lr-min_lr)/n_epochs\n",
    "            for batch in batch_iterator:\n",
    "                b = batch\n",
    "                tic = time()\n",
    "                print \"norm V: \" + str(np.linalg.norm(self.V.get_value()))\n",
    "                cost,activations,prediction,output,grads1 = self._train(b, learning_rate)\n",
    "                print np.max(activations)\n",
    "                for i in activations:\n",
    "                    print i,\n",
    "                print \"\"\n",
    "                for i in prediction:\n",
    "                    print i,\n",
    "                print \"\"\n",
    "                print np.sum(prediction)\n",
    "                print np.argmax(prediction)\n",
    "                for i in output:\n",
    "                    print i,\n",
    "                toc = time() - tic\n",
    "                n_iter += 1\n",
    "                if not n_iter%save_every:\n",
    "                    if verbose:\n",
    "                        print \"\\tSaving model\"\n",
    "                    self.save(saving_path)\n",
    "                if n_iter==n_epochs:\n",
    "                    break_all = True\n",
    "                if verbose:\n",
    "                    print \"Epoch %d Update %d Cost %f Time %fs\" % (epoch,\n",
    "                                                                   n_iter, \n",
    "                                                                   cost, \n",
    "                                                                   toc)\n",
    "                if np.isnan(grads1).any():\n",
    "                    print \"stop because of grads1\"\n",
    "                if np.isnan(cost):\n",
    "                    break_all = True\n",
    "                if break_all:\n",
    "                    break\n",
    "            if break_all:\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "batches = MinibatchSentenceIt(path, 3, w2i,tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/ipykernel/__main__.py:43: UserWarning: theano.function was asked to create a function computing outputs given certain inputs, but the provided input variable at index 1 is not part of the computational graph needed to compute the outputs: lr.\n",
      "To make this warning into an error, you can pass the parameter on_unused_input='raise' to theano.function. To disable it completely, use on_unused_input='ignore'.\n"
     ]
    }
   ],
   "source": [
    "model1 = FastSent.create(vocab_size, dim,w2i=w2i,i2e=i2e,cst=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "norm V: 17.385\n",
      "307.247\n",
      "[  0.00000000e+00   2.26943573e+02   6.09856224e+01   1.64802948e+02\n",
      "   1.74409424e+02   2.14155655e+01   1.32498190e-01  -5.51832557e-01\n",
      "  -3.18536282e-01   3.77494278e+01   2.26036301e+01   1.54559600e+00\n",
      "   2.59831200e+01  -1.12183258e-01   3.13861161e-01  -3.66684198e-01\n",
      "   6.50928574e+01  -1.67141449e+00   2.66910980e+02  -3.33939821e-01\n",
      "  -1.53493226e-01   2.73550957e-01   9.64015884e+01   3.56405716e+01\n",
      "   7.24593341e-01  -9.09662992e-02   3.24163399e+01   5.54148778e-02\n",
      "   3.20624466e+01   4.82878268e-01   5.08219779e-01   3.65635757e+01\n",
      "  -8.01636755e-01   7.68050461e+01  -1.81703299e-01   2.69702835e+01\n",
      "   3.00479946e+01   6.11308632e+01   9.52913463e-01   2.57305725e+02\n",
      "  -3.01163197e-01   1.29099622e-01  -3.84017676e-01  -7.29373470e-02\n",
      "   3.35973829e-01   3.07246674e+02   6.39380157e-01   3.08792152e+01\n",
      "   2.63733521e+02   2.55853252e+01   4.17190313e-01   2.63426483e-01\n",
      "   3.48912805e-01   2.91370773e+01   3.57279599e-01] \n",
      "[  0.00000000e+00   1.33292751e-35   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   3.03690325e-18   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   2.04607547e-22\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   1.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   1.26612840e-19   0.00000000e+00   0.00000000e+00   0.00000000e+00\n",
      "   0.00000000e+00   0.00000000e+00   0.00000000e+00] \n",
      "1.0\n",
      "45\n",
      "[  1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000100e+00\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000100e+00   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000100e+00   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06   1.00000000e-06   1.00000000e-06   1.00000000e-06\n",
      "   1.00000000e-06] Epoch 0 Update 1 Cost 815.115120 Time 0.010708s\n"
     ]
    }
   ],
   "source": [
    "model1.train(batches, \n",
    "            lr=lr, \n",
    "            min_lr=lr/float(100), \n",
    "            n_epochs=1, \n",
    "            saving_path=saving_path, \n",
    "            save_every=save_every, \n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python2.7/dist-packages/traitlets/traitlets.py:463: DeprecationWarning: _[traitname]_default handlers are deprecated: use default decorator instead\n",
      "  dynamic_default = self._dynamic_default_callable(obj)\n",
      "/usr/local/lib/python2.7/dist-packages/traitlets/traitlets.py:981: DeprecationWarning: _[traitname]_changed handlers are deprecated: use observe and unobserve instead\n",
      "  'type': 'change',\n",
      "/usr/local/lib/python2.7/dist-packages/traitlets/traitlets.py:451: DeprecationWarning: _[traitname]_default handlers are deprecated: use default decorator instead\n",
      "  if (self._dynamic_default_callable(obj) is None) \\\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-309.36353"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import math\n",
    "math.log(math.exp(-1.37853)/math.exp(307.985))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2 = FastSent.create(vocab_size, dim,w2i=w2i,i2e=i2e,cst=0.001)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model2.train(batches, \n",
    "            lr=lr, \n",
    "            min_lr=lr/float(100), \n",
    "            n_epochs=10, \n",
    "            saving_path=saving_path, \n",
    "            save_every=save_every, \n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model.train(batches, \n",
    "            lr=lr, \n",
    "            min_lr=lr/float(100), \n",
    "            n_epochs=20, \n",
    "            saving_path=saving_path, \n",
    "            save_every=save_every, \n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelNoInit = FastSent.create(vocab_size, dim,w2i=w2i)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "modelNoInit.train(batches, \n",
    "            lr=lr, \n",
    "            min_lr=lr/float(100), \n",
    "            n_epochs=5, \n",
    "            saving_path=saving_path, \n",
    "            save_every=save_every, \n",
    "            verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
